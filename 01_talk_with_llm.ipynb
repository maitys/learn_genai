{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a73331",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    font-family: 'DM Sans', sans-serif;\n",
    "    font-size: 24px;\n",
    "    font-weight: bold;\n",
    "    color: #ff5733; \n",
    "    background-color: #f5f5dc; \n",
    "    padding: 10px; \n",
    "    border-radius: 10px;\n",
    "    text-align: center;\n",
    "    box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);\">\n",
    "    1 - Talk with LLM<br> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9045a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d5589d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69ceb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n",
      "\n",
      "\n",
      "The financial capital of India is Mumbai. \n",
      "\n",
      "Two bullet points about Mumbai as the financial capital of India are:\n",
      "\n",
      "1. Mumbai is home to the Bombay Stock Exchange, the oldest stock exchange in Asia and one of the largest in the world, making it a major hub for stock trading and investment in India.\n",
      "\n",
      "2. The Reserve Bank of India, the central banking institution of the country, is located in Mumbai, making it a key center for financial policy and regulation in India."
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/integrations/llms/\n",
    "\n",
    "# Completion Model\n",
    "from langchain_openai import OpenAI\n",
    "llm_model = OpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000)\n",
    "\n",
    "response = llm_model.invoke(\"What is the capital of India?\")\n",
    "print(response)\n",
    "\n",
    "for chunk in llm_model.stream(\"What is the financial capital of India? Tell me 2 bullet points about it\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645a78b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "content='The capital of India is New Delhi.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 23, 'total_tokens': 108, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_e20469f047', 'id': 'chatcmpl-BilBVtP58XtbFT8T15iqSWhF5nPDx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--c838ca17-172e-49e6-9182-8a4da94272de-0' usage_metadata={'input_tokens': 23, 'output_tokens': 85, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}\n",
      "********************\n",
      "The capital of India is New Delhi.\n",
      "********************\n",
      "{'$defs': {'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9', 'properties': {'audio': {'title': 'Audio', 'type': 'integer'}, 'cache_creation': {'title': 'Cache Creation', 'type': 'integer'}, 'cache_read': {'title': 'Cache Read', 'type': 'integer'}}, 'title': 'InputTokenDetails', 'type': 'object'}, 'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)', 'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}, 'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'}, 'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}, 'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Error'}, 'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}}, 'required': ['name', 'args', 'id', 'error'], 'title': 'InvalidToolCall', 'type': 'object'}, 'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9', 'properties': {'audio': {'title': 'Audio', 'type': 'integer'}, 'reasoning': {'title': 'Reasoning', 'type': 'integer'}}, 'title': 'OutputTokenDetails', 'type': 'object'}, 'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".', 'properties': {'name': {'title': 'Name', 'type': 'string'}, 'args': {'additionalProperties': True, 'title': 'Args', 'type': 'object'}, 'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}, 'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}}, 'required': ['name', 'args', 'id'], 'title': 'ToolCall', 'type': 'object'}, 'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.', 'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'}, 'output_tokens': {'title': 'Output Tokens', 'type': 'integer'}, 'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}, 'input_token_details': {'$ref': '#/$defs/InputTokenDetails'}, 'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}}, 'required': ['input_tokens', 'output_tokens', 'total_tokens'], 'title': 'UsageMetadata', 'type': 'object'}}, 'additionalProperties': True, 'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.', 'properties': {'content': {'anyOf': [{'type': 'string'}, {'items': {'anyOf': [{'type': 'string'}, {'additionalProperties': True, 'type': 'object'}]}, 'type': 'array'}], 'title': 'Content'}, 'additional_kwargs': {'additionalProperties': True, 'title': 'Additional Kwargs', 'type': 'object'}, 'response_metadata': {'additionalProperties': True, 'title': 'Response Metadata', 'type': 'object'}, 'type': {'const': 'ai', 'default': 'ai', 'title': 'Type', 'type': 'string'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Name'}, 'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Id'}, 'example': {'default': False, 'title': 'Example', 'type': 'boolean'}, 'tool_calls': {'default': [], 'items': {'$ref': '#/$defs/ToolCall'}, 'title': 'Tool Calls', 'type': 'array'}, 'invalid_tool_calls': {'default': [], 'items': {'$ref': '#/$defs/InvalidToolCall'}, 'title': 'Invalid Tool Calls', 'type': 'array'}, 'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'}, {'type': 'null'}], 'default': None}}, 'required': ['content'], 'title': 'AIMessage', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# Chat Model\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm_model = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model=\"o3-mini\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of India?\"}\n",
    "]\n",
    "\n",
    "result = llm_model.invoke(messages)\n",
    "type(result)\n",
    "print(\"*\" * 20)\n",
    "type(result.content)\n",
    "print(\"*\" * 20)\n",
    "print(result)\n",
    "print(\"*\" * 20)\n",
    "print(result.content)\n",
    "print(\"*\" * 20)\n",
    "print(result.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c301d869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "content='- **Location**: The financial capital of India is Mumbai, located in the state of Maharashtra.\\n- **Economic Hub**: Mumbai serves as the economic heart of India, housing major financial institutions such as the Bombay Stock Exchange (BSE), National Stock Exchange of India (NSE), and the Reserve Bank of India (RBI).' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 26, 'total_tokens': 94, 'completion_time': 0.206060606, 'prompt_time': 0.00256947, 'queue_time': 0.21869543300000002, 'total_time': 0.208630076}, 'model_name': 'mistral-saba-24b', 'system_fingerprint': 'fp_07e680a590', 'finish_reason': 'stop', 'logprobs': None} id='run--b5518e0b-0e3c-4941-8f68-385537e9c75c-0' usage_metadata={'input_tokens': 26, 'output_tokens': 68, 'total_tokens': 94}\n",
      "********************\n",
      "- **Location**: The financial capital of India is Mumbai, located in the state of Maharashtra.\n",
      "- **Economic Hub**: Mumbai serves as the economic heart of India, housing major financial institutions such as the Bombay Stock Exchange (BSE), National Stock Exchange of India (NSE), and the Reserve Bank of India (RBI).\n",
      "********************\n",
      "{'$defs': {'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9', 'properties': {'audio': {'title': 'Audio', 'type': 'integer'}, 'cache_creation': {'title': 'Cache Creation', 'type': 'integer'}, 'cache_read': {'title': 'Cache Read', 'type': 'integer'}}, 'title': 'InputTokenDetails', 'type': 'object'}, 'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)', 'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}, 'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'}, 'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}, 'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Error'}, 'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}}, 'required': ['name', 'args', 'id', 'error'], 'title': 'InvalidToolCall', 'type': 'object'}, 'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9', 'properties': {'audio': {'title': 'Audio', 'type': 'integer'}, 'reasoning': {'title': 'Reasoning', 'type': 'integer'}}, 'title': 'OutputTokenDetails', 'type': 'object'}, 'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".', 'properties': {'name': {'title': 'Name', 'type': 'string'}, 'args': {'additionalProperties': True, 'title': 'Args', 'type': 'object'}, 'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}, 'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}}, 'required': ['name', 'args', 'id'], 'title': 'ToolCall', 'type': 'object'}, 'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.', 'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'}, 'output_tokens': {'title': 'Output Tokens', 'type': 'integer'}, 'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}, 'input_token_details': {'$ref': '#/$defs/InputTokenDetails'}, 'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}}, 'required': ['input_tokens', 'output_tokens', 'total_tokens'], 'title': 'UsageMetadata', 'type': 'object'}}, 'additionalProperties': True, 'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.', 'properties': {'content': {'anyOf': [{'type': 'string'}, {'items': {'anyOf': [{'type': 'string'}, {'additionalProperties': True, 'type': 'object'}]}, 'type': 'array'}], 'title': 'Content'}, 'additional_kwargs': {'additionalProperties': True, 'title': 'Additional Kwargs', 'type': 'object'}, 'response_metadata': {'additionalProperties': True, 'title': 'Response Metadata', 'type': 'object'}, 'type': {'const': 'ai', 'default': 'ai', 'title': 'Type', 'type': 'string'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Name'}, 'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Id'}, 'example': {'default': False, 'title': 'Example', 'type': 'boolean'}, 'tool_calls': {'default': [], 'items': {'$ref': '#/$defs/ToolCall'}, 'title': 'Tool Calls', 'type': 'array'}, 'invalid_tool_calls': {'default': [], 'items': {'$ref': '#/$defs/InvalidToolCall'}, 'title': 'Invalid Tool Calls', 'type': 'array'}, 'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'}, {'type': 'null'}], 'default': None}}, 'required': ['content'], 'title': 'AIMessage', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# Chat Model\n",
    "from langchain_groq import ChatGroq\n",
    "llm_model = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model=\"mistral-saba-24b\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the financial capital of India? Write 2 bullet points about it.\"}\n",
    "]\n",
    "\n",
    "result = llm_model.invoke(messages)\n",
    "type(result)\n",
    "print(\"*\" * 20)\n",
    "type(result.content)\n",
    "print(\"*\" * 20)\n",
    "print(result)\n",
    "print(\"*\" * 20)\n",
    "print(result.content)\n",
    "print(\"*\" * 20)\n",
    "print(result.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22015f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume at lecture 17 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_env1_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
